---
title: "03_preprocess_data"
author: "Jae Yeon Kim"
date: "7/2/2020"
output: html_document
---

# Import packages and files 

## Packages

```{r}

pacman::p_load(tidyverse, # for tidyverse 
               ggpubr, # for arranging ggplots   
               ggthemes, # for fancy ggplot themes
               here, # for reproducibility 
               patchwork, # for easy ggarrange
               ggsci, # for pubs 
               fastDummies, # to create dummy variables fast
               readtext, # for reading text
               quanteda, # for text preprocessing 
               data.table, # for fast data manipulation
               stm, # for structural topic modeling
               future, # for parallel and distributed computing      
               purrr) # for functional programming 

# for publication-friendly theme 
theme_set(theme_pubr())

# custom functions
source(here("functions", "stacked_bar_plot.R"))
source(here("functions", "visualize_diag.R"))

# For keyword based topic modeling (development version)
devtools::install_github("keyATM/keyATM", ref = "package_dev")

library(keyATM)
```

## Files 

- Filter 90% of the data (by `chinese` and `wuhan` variables)

```{r}

# Subset 
df <- data.table::fread(here("processed_data", "cleaned_data.csv"))[,-1] 

small_df <- df %>% filter(chinese == 1 | wuhan == 1 | asian == 1)

1 - nrow(small_df)/nrow(df)

# Filter (doc length 0 ones)

small_df <- small_df[-c(2930, 25557, 33569, 49215, 49782, 51570, 71263, 89443, 102349, 110336, 120622, 121199, 122278, 122673, 125622, 133019),]
```

# Preprocess 

```{r}

# Build a corpus 
my_corpus <- corpus(small_df$full_text)

# Add the document-level covariates 
docvars(my_corpus, "wuhan") <- small_df$wuhan

docvars(my_corpus, "asian") <- small_df$asian

docvars(my_corpus, 
"chinese") <- small_df$chinese

docvars(my_corpus, 
"date") <- small_df$date

# Check the document-level covariates 
head(docvars(my_corpus))

# Time index  

index <- as.integer(gsub("-", "", docvars(my_corpus)$date))

docvars(my_corpus, "index") <- c(index - min(index) + 1)

# Check 
docvars(my_corpus) %>%
  arrange(date)
```

```{r}
# Tokenize 
data_tokens <- tokens(my_corpus,
                      remove_url = TRUE) %>%
    tokens_remove(c(stopwords("english"),
                               "may", "shall", "can",
                               "must", "upon", "with", "without")) 

```

# Document-term matrix 

```{r}
# Construct a document-term matrix 

data_dfm <- dfm(data_tokens) %>%
    dfm_trim(min_termfreq = 100, 
             min_docfreq = 100)

```


```{r}
# write_rds(data_dfm, here("processed_data", "data_dfm.rds"))

data_dfm <- read_rds(here("processed_data", "data_dfm.rds"))
```

# KeyATM

## Prepare the data 

```{r}
# Prepare the data for keyATM

# future::plan("multiprocess")

tictoc::tic()
keyATM_docs <- keyATM_read(texts = data_dfm)
tictoc::toc()

# 239.947 sec elapsed

```

```{r}

# Export 
# write_rds(keyATM_docs, here("processed_data", 
 #                           "keyATM_docs.rds"))

keyATM_docs <- read_rds(here("processed_data", "keyATM_docs.rds"))
```

## Create a dictionary of the key words 

```{r}

# Keywords 

keywords <- list(anti_chinese = c("wuhanvirus", "chinesevirus", "chinavirus", "wuhancoronavirus", "wuhanpneumonia"))

```


## Check keywords 

```{r}

key_viz <- visualize_keywords(docs = keyATM_docs, 
                              keywords = keywords)

save_fig(key_viz, here("outputs", "keyword.png")) 

vf <- values_fig(key_viz) 

```

## Number of K

```{r}

# Run many models 
many_models <- tibble(K = c(2:5)) %>%
               mutate(topic_model = furrr::future_map(K, ~stm(data_dfm, 
                                                       K = .,
                                                       verbose = TRUE)))

write_rds(many_models, here("outputs", "many_models.rds"))


# Resolve conflicts 
conflicted::conflict_prefer("purrr", "map")

k_search_diag <- visualize_diag(data_dfm, many_models)

ggsave(here("outputs", "k_search_diag.png"))
```

## Base model 

```{r}

future::plan("multiprocess")

out <- keyATM(docs = keyATM_docs,    # text input
              no_keyword_topics = 3,              # number of topics without keywords
              keywords = keywords,       # keywords
              model = "base",         # select the model
              options = list(seed = 250))

write_rds(out, here("outputs", "keyATM_out.rds"))

```

```{r}

# Check the tod words 
top_words(out) 

```

```{r}

topic_out <- tibble(topic_counts = out$topic_counts,
                    names = c("Anti-Asian", "Others". "Others". "Others"))

topic_out %>% 
    mutate(prop = topic_counts / sum(topic_counts),
           prop = round(prop,2)) %>%
    ggplot(aes(x = names, y = prop)) +
    geom_col() +
    scale_y_continuous(labels =    
    scales::percent_format(accuracy = 1)) +
    labs(x = "Names", y = "Proportion", 
          title = "Topic distributions",
          subtitle = "Only used the Tweets mentioned either Asian, Chinese, or Wuhan related words") 

ggsave(here("outputs", "topic_modeling_base.png"))
    
```

## Dynamic model

```{r}

future::plan("multiprocess")

dynamic_out <- keyATM(docs = keyATM_docs,    # text input
              no_keyword_topics = 3,              # number of topics without keywords
              keywords = keywords,       # keywords
              model = "dynamic",         # select the model
              model_settings = list(time_index = docvars(my_corpus)$index,
                                    num_states = 5),
              options = list(seed = 250))
 
write_rds(dynamic_out, here("outputs", "dynamic_out.rds"))

```

